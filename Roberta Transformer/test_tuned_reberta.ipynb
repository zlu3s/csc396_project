{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c4f70be",
   "metadata": {},
   "source": [
    "<p style=\"font-size:44px; text-align:center; font-weight:bold\">\n",
    "    Fine-tuning for poems and songs\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f34d2a9",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px\">\n",
    "    Initialize for consitency\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef379397-4c75-4aee-a3d1-7b3c5c4f1520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "random seed: 1234\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "# enable tqdm in pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# set to True to use the gpu (if there is one available)\n",
    "use_gpu = True\n",
    "\n",
    "# select device\n",
    "device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {device.type}')\n",
    "\n",
    "# random seed\n",
    "seed = 1234\n",
    "\n",
    "# set random seed\n",
    "if seed is not None:\n",
    "    print(f'random seed: {seed}')\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca26105",
   "metadata": {},
   "source": [
    "<p style=\"font-size:35px; text-align:center; font-weight:bold\">\n",
    "    Pre-tuning setup\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd9b441",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px; font-weight:bold\">\n",
    "    Import tuned roberta model\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f620b70f-29db-4ee2-aa3c-668bfcab00a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "name = './roberta-base-sentiments'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(name)\n",
    "model = RobertaForSequenceClassification.from_pretrained(name)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0dd111",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px; font-weight:bold\">\n",
    "    Import and adjust datasets used for tuning and testing\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4fe023c-dead-4aba-a72a-b95925967d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Importing the datasets\n",
    "\"\"\"\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "# Songs\n",
    "kg_songs = load_dataset(\"csv\", data_files=\"../datasets/songs.csv\")\n",
    "kg_songs = kg_songs[\"train\"].to_pandas()\n",
    "\n",
    "# Poems\n",
    "kg_poems = load_dataset(\"csv\", data_files=\"../datasets/final_df_emotions(remove-bias).csv\")\n",
    "kg_poems = kg_poems[\"train\"].to_pandas()\n",
    "\n",
    "md_perc = pd.read_excel(\"../datasets/PERC_mendelly.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69a2c9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adjusting the datasets\n",
    "\"\"\"\n",
    "\n",
    "# Rename columns for consistency\n",
    "kg_songs = kg_songs.rename(columns={\"mood\": \"label\", \"lyrics\": \"text\"})\n",
    "kg_poems = kg_poems.rename(columns={\"poem content\": \"text\"})\n",
    "md_perc = md_perc.rename(columns={\"Emotion\": \"label\", \"Poem\": \"text\"})\n",
    "\n",
    "labels = [\"sad\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "label_map = {\n",
    "    \"sad\": 0,\n",
    "    \"sadness\": 0,\n",
    "    \"joy\": 1,\n",
    "    \"happy\": 1,\n",
    "    \"love\": 2,\n",
    "    \"romantic\": 2,\n",
    "    \"anger\": 3,\n",
    "    \"angry\": 3,\n",
    "    \"fear\": 4,\n",
    "    \"surprise\": 5,\n",
    "    \"excited\": 5\n",
    "}\n",
    "\n",
    "# Adjust labels to match the model's expected input\n",
    "def adjust_labels(df, label_col, label_map):\n",
    "    \"\"\"\n",
    "    This will drop rows that do not have labels in the label_map\n",
    "    \"\"\"\n",
    "    df[label_col] = df[label_col].map(label_map)\n",
    "    return df[df[label_col].isin([0,1,2,3,4,5])].reset_index(drop=True)\n",
    "\n",
    "kg_songs = adjust_labels(kg_songs, \"label\", label_map)\n",
    "kg_poems = adjust_labels(kg_poems, \"label\", label_map)\n",
    "md_perc = adjust_labels(md_perc, \"label\", label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6f743e",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px; font-weight:bold\">\n",
    "    Seperate datasets into further training and testing datasets\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9f2e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_songs_ds = Dataset.from_pandas(kg_songs)\n",
    "kg_poems_ds = Dataset.from_pandas(kg_poems)\n",
    "md_perc_ds = Dataset.from_pandas(md_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "710a297e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['song_name', 'artist', 'text', 'label'],\n",
      "    num_rows: 498\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(kg_songs_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "342bb5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9991018d76a6481a91f84157b729b344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/498 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60830563dcf541a5beaf370946a02dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/374 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce38a21f9109477f97a94206324e31be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/536 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "def tokenize(dataset):\n",
    "    return tokenizer(dataset['text'], truncation=True, padding='max_length')\n",
    "\n",
    "test1 = kg_songs_ds.map(\n",
    "    tokenize, batched=True,\n",
    "    remove_columns=['song_name', 'artist'],\n",
    ")\n",
    "\n",
    "test2 = kg_poems_ds.map(\n",
    "    tokenize, batched=True,\n",
    "    remove_columns=['pred', 'score', 'anger', 'fear', 'joy', 'disgust', 'sadness', 'surprise', 'neutral'],\n",
    ")\n",
    "\n",
    "test3 = md_perc_ds.map(\n",
    "    tokenize, batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91ed4ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07be7bd37ca54d66aa3da46cbc699acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/498 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2bb4667ebf4348b7be3564487a9d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/374 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7a8bb19e6343eeba7aea75f0984eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/536 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Value\n",
    "\n",
    "test1 = test1.cast_column(\"label\", Value(\"int64\"))\n",
    "test2 = test2.cast_column(\"label\", Value(\"int64\"))\n",
    "test3 = test3.cast_column(\"label\", Value(\"int64\"))\n",
    "trainer = Trainer(model=model)\n",
    "output1 = trainer.predict(test1)\n",
    "output2 = trainer.predict(test2)\n",
    "output3 = trainer.predict(test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a28109d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         sad       0.13      0.02      0.04        95\n",
      "         joy       0.21      0.42      0.28       106\n",
      "        love       0.29      0.03      0.05        73\n",
      "       anger       0.24      0.50      0.32       113\n",
      "        fear       0.00      0.00      0.00         0\n",
      "    surprise       0.00      0.00      0.00       111\n",
      "\n",
      "    accuracy                           0.21       498\n",
      "   macro avg       0.14      0.16      0.12       498\n",
      "weighted avg       0.17      0.21      0.15       498\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csc396_7/miniconda3/envs/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/csc396_7/miniconda3/envs/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/csc396_7/miniconda3/envs/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "labels = [\"sad\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "y_true = output1.label_ids\n",
    "y_pred = np.argmax(output1.predictions, axis=-1)\n",
    "target_names = labels\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99b971d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         sad       0.45      0.29      0.35       143\n",
      "         joy       0.13      0.79      0.22        24\n",
      "        love       0.00      0.00      0.00         0\n",
      "       anger       0.33      0.37      0.35        67\n",
      "        fear       0.73      0.17      0.28       128\n",
      "    surprise       0.50      0.25      0.33        12\n",
      "\n",
      "    accuracy                           0.29       374\n",
      "   macro avg       0.36      0.31      0.26       374\n",
      "weighted avg       0.51      0.29      0.32       374\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csc396_7/miniconda3/envs/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/csc396_7/miniconda3/envs/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/csc396_7/miniconda3/envs/main/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "y_true = output2.label_ids\n",
    "y_pred = np.argmax(output2.predictions, axis=-1)\n",
    "target_names = labels\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8037fddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         sad       0.36      0.37      0.36       154\n",
      "         joy       0.31      0.45      0.37       128\n",
      "        love       0.70      0.20      0.31       161\n",
      "       anger       0.14      0.24      0.17        46\n",
      "        fear       0.12      0.19      0.15        31\n",
      "    surprise       0.25      0.19      0.21        16\n",
      "\n",
      "    accuracy                           0.31       536\n",
      "   macro avg       0.31      0.27      0.26       536\n",
      "weighted avg       0.41      0.31      0.31       536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = output3.label_ids\n",
    "y_pred = np.argmax(output3.predictions, axis=-1)\n",
    "target_names = labels\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242f26b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
