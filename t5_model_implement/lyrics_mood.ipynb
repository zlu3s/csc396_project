{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8adeb89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/Users/cheepheng/miniconda3/envs/csc396/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/Users/cheepheng/miniconda3/envs/csc396/lib/python3.12/site-packages/transformers/models/auto/modeling_auto.py:1748: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-emotion\")\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-emotion\")\n",
    "\n",
    "def get_emotion(text):\n",
    "  input_ids = tokenizer.encode(text + '</s>', return_tensors='pt', max_length=512,\n",
    "  truncation=True)\n",
    "\n",
    "  output = model.generate(input_ids=input_ids,\n",
    "               max_length=2)\n",
    "  \n",
    "  dec = [tokenizer.decode(ids) for ids in output]\n",
    "  label = dec[0]\n",
    "  return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd293473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "lyrics = pd.read_csv('datasets/spotify_millsongdata.csv')\n",
    "all_lyrics = lyrics['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff702f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 18/57650 [00:07<6:31:53,  2.45it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      2\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mpandas()\n\u001b[0;32m----> 4\u001b[0m lyrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmood\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lyrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mprogress_apply(get_emotion)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_emotion_with_progress\u001b[39m(text, index, total):\n\u001b[1;32m      7\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# Print every 10th item\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/tqdm/std.py:917\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(df, df_function)(wrapper, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    919\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/tqdm/std.py:912\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m, in \u001b[0;36mget_emotion\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_emotion\u001b[39m(text):\n\u001b[1;32m      8\u001b[0m   input_ids \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(text \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m</s>\u001b[39m\u001b[38;5;124m'\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m      9\u001b[0m   truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 11\u001b[0m   output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m     12\u001b[0m                max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     14\u001b[0m   dec \u001b[38;5;241m=\u001b[39m [tokenizer\u001b[38;5;241m.\u001b[39mdecode(ids) \u001b[38;5;28;01mfor\u001b[39;00m ids \u001b[38;5;129;01min\u001b[39;00m output]\n\u001b[1;32m     15\u001b[0m   label \u001b[38;5;241m=\u001b[39m dec[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/transformers/generation/utils.py:1745\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_attention_mask_for_generation(\n\u001b[1;32m   1740\u001b[0m         inputs_tensor, generation_config\u001b[38;5;241m.\u001b[39m_pad_token_tensor, generation_config\u001b[38;5;241m.\u001b[39m_eos_token_tensor\n\u001b[1;32m   1741\u001b[0m     )\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[1;32m   1744\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created and added to `model_kwargs`\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_encoder_decoder_kwargs_for_generation(\n\u001b[1;32m   1746\u001b[0m         inputs_tensor, model_kwargs, model_input_name, generation_config\n\u001b[1;32m   1747\u001b[0m     )\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/transformers/generation/utils.py:549\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name, generation_config)\u001b[0m\n\u001b[1;32m    547\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    548\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[0;32m--> 549\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m encoder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoder_kwargs)\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:1106\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1091\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1092\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1093\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1103\u001b[0m         output_attentions,\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1106\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[1;32m   1107\u001b[0m         hidden_states,\n\u001b[1;32m   1108\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   1109\u001b[0m         position_bias\u001b[38;5;241m=\u001b[39mposition_bias,\n\u001b[1;32m   1110\u001b[0m         encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[1;32m   1111\u001b[0m         encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[1;32m   1112\u001b[0m         encoder_decoder_position_bias\u001b[38;5;241m=\u001b[39mencoder_decoder_position_bias,\n\u001b[1;32m   1113\u001b[0m         layer_head_mask\u001b[38;5;241m=\u001b[39mlayer_head_mask,\n\u001b[1;32m   1114\u001b[0m         cross_attn_layer_head_mask\u001b[38;5;241m=\u001b[39mcross_attn_layer_head_mask,\n\u001b[1;32m   1115\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_value,\n\u001b[1;32m   1116\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1117\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1118\u001b[0m     )\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:686\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    684\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 686\u001b[0m self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer[\u001b[38;5;241m0\u001b[39m](\n\u001b[1;32m    687\u001b[0m     hidden_states,\n\u001b[1;32m    688\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    689\u001b[0m     position_bias\u001b[38;5;241m=\u001b[39mposition_bias,\n\u001b[1;32m    690\u001b[0m     layer_head_mask\u001b[38;5;241m=\u001b[39mlayer_head_mask,\n\u001b[1;32m    691\u001b[0m     past_key_value\u001b[38;5;241m=\u001b[39mself_attn_past_key_value,\n\u001b[1;32m    692\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    693\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    694\u001b[0m )\n\u001b[1;32m    695\u001b[0m hidden_states, present_key_value_state \u001b[38;5;241m=\u001b[39m self_attention_outputs[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    696\u001b[0m attention_outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m2\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:593\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    584\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    591\u001b[0m ):\n\u001b[1;32m    592\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 593\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSelfAttention(\n\u001b[1;32m    594\u001b[0m         normed_hidden_states,\n\u001b[1;32m    595\u001b[0m         mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    596\u001b[0m         position_bias\u001b[38;5;241m=\u001b[39mposition_bias,\n\u001b[1;32m    597\u001b[0m         layer_head_mask\u001b[38;5;241m=\u001b[39mlayer_head_mask,\n\u001b[1;32m    598\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_value,\n\u001b[1;32m    599\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    600\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    601\u001b[0m     )\n\u001b[1;32m    602\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    603\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (hidden_states,) \u001b[38;5;241m+\u001b[39m attention_output[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/transformers/models/t5/modeling_t5.py:553\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    550\u001b[0m     position_bias_masked \u001b[38;5;241m=\u001b[39m position_bias\n\u001b[1;32m    552\u001b[0m scores \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m position_bias_masked\n\u001b[0;32m--> 553\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(scores\u001b[38;5;241m.\u001b[39mfloat(), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtype_as(\n\u001b[1;32m    554\u001b[0m     scores\n\u001b[1;32m    555\u001b[0m )  \u001b[38;5;66;03m# (batch_size, n_heads, seq_length, key_length)\u001b[39;00m\n\u001b[1;32m    556\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(\n\u001b[1;32m    557\u001b[0m     attn_weights, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining\n\u001b[1;32m    558\u001b[0m )  \u001b[38;5;66;03m# (batch_size, n_heads, seq_length, key_length)\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;66;03m# Mask heads if we want to\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/csc396/lib/python3.12/site-packages/torch/nn/functional.py:2140\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   2138\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   2139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2140\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim)\n\u001b[1;32m   2141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2142\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "lyrics['mood'] = lyrics['text'].progress_apply(get_emotion)\n",
    "\n",
    "def get_emotion_with_progress(text, index, total):\n",
    "  if index % 10 == 0:  # Print every 10th item\n",
    "      print(f\"Processing {index}/{total}\")\n",
    "  return get_emotion(text)\n",
    "\n",
    "total = len(lyrics)\n",
    "lyrics['mood'] = [get_emotion_with_progress(text, i, total)\n",
    "                for i, text in enumerate(lyrics['text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65e9af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics['mood'] = lyrics['text'].apply(get_emotion)\n",
    "print(lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b101f936",
   "metadata": {},
   "source": [
    "## Probability Distribution Function\n",
    "New function to get emotion probability distributions instead of just a single label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "434536fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load model using the recommended class\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"mrm8488/t5-base-finetuned-emotion\")\n",
    "\n",
    "# Emotion token IDs (discovered from model testing)\n",
    "EMOTION_IDS = {\n",
    "    'joy': 3922,\n",
    "    'sadness': 24784,\n",
    "    'anger': 11213,\n",
    "    'fear': 2971,\n",
    "    'love': 333,\n",
    "    'surprise': 4158\n",
    "}\n",
    "\n",
    "def get_emotion_distribution(text):\n",
    "    \"\"\"\n",
    "    Get probability distribution over all emotions for a given text.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text (song lyrics)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with emotion labels as keys and probabilities as values\n",
    "        e.g., {'joy': 0.85, 'sadness': 0.10, 'anger': 0.02, ...}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Tokenize input\n",
    "        input_ids = tokenizer.encode(text + '</s>', return_tensors='pt', max_length=512, truncation=True)\n",
    "        \n",
    "        # Get model output with logits\n",
    "        with torch.no_grad():\n",
    "            decoder_start_token_id = model.config.decoder_start_token_id\n",
    "            decoder_input_ids = torch.tensor([[decoder_start_token_id]])\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, decoder_input_ids=decoder_input_ids)\n",
    "            logits = outputs.logits[0, 0, :]  # First token position\n",
    "            \n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            \n",
    "            # Extract probabilities for each emotion\n",
    "            emotion_probs = {}\n",
    "            for emotion, token_id in EMOTION_IDS.items():\n",
    "                emotion_probs[emotion] = float(probs[token_id].item())\n",
    "            \n",
    "            return emotion_probs\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        # Return uniform distribution on error\n",
    "        return {emotion: 1.0/len(EMOTION_IDS) for emotion in EMOTION_IDS.keys()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119c8cb3",
   "metadata": {},
   "source": [
    "## Test on First 10 Songs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd890db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Total songs in dataset: 57650\n",
      "\n",
      "Dataset columns: ['artist', 'song', 'link', 'text']\n",
      "\n",
      "Processing first 10 songs...\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the dataset\n",
    "print(\"Loading dataset...\")\n",
    "lyrics_df = pd.read_csv('datasets/spotify_millsongdata.csv')\n",
    "\n",
    "print(f\"Total songs in dataset: {len(lyrics_df)}\")\n",
    "print(f\"\\nDataset columns: {lyrics_df.columns.tolist()}\")\n",
    "\n",
    "# Get first 10 songs for testing\n",
    "test_df = lyrics_df.head(10).copy()\n",
    "\n",
    "print(f\"\\nProcessing first 10 songs...\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05215f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing songs:  10%|█         | 1/10 [00:00<00:08,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Song 1:\n",
      "  Text preview: Look at her face, it's a wonderful face  \n",
      "And it means something special to me  \n",
      "Look at the way t...\n",
      "  Original prediction: <pad> joy\n",
      "  Probability distribution:\n",
      "    joy       : 0.9996 (99.96%)\n",
      "    love      : 0.0003 (0.03%)\n",
      "    sadness   : 0.0000 (0.00%)\n",
      "    surprise  : 0.0000 (0.00%)\n",
      "    anger     : 0.0000 (0.00%)\n",
      "    fear      : 0.0000 (0.00%)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing songs:  20%|██        | 2/10 [00:01<00:07,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Song 2:\n",
      "  Text preview: Take it easy with me, please  \n",
      "Touch me gently like a summer evening breeze  \n",
      "Take your time, make...\n",
      "  Original prediction: <pad> love\n",
      "  Probability distribution:\n",
      "    love      : 0.9602 (96.02%)\n",
      "    joy       : 0.0388 (3.88%)\n",
      "    sadness   : 0.0003 (0.03%)\n",
      "    surprise  : 0.0001 (0.01%)\n",
      "    anger     : 0.0001 (0.01%)\n",
      "    fear      : 0.0000 (0.00%)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing songs:  30%|███       | 3/10 [00:02<00:06,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Song 3:\n",
      "  Text preview: I'll never know why I had to go  \n",
      "Why I had to put up such a lousy rotten show  \n",
      "Boy, I was tough,...\n",
      "  Original prediction: <pad> sadness\n",
      "  Probability distribution:\n",
      "    sadness   : 0.9332 (93.32%)\n",
      "    joy       : 0.0481 (4.81%)\n",
      "    anger     : 0.0123 (1.23%)\n",
      "    fear      : 0.0031 (0.31%)\n",
      "    love      : 0.0021 (0.21%)\n",
      "    surprise  : 0.0001 (0.01%)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing songs:  40%|████      | 4/10 [00:03<00:05,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Song 4:\n",
      "  Text preview: Making somebody happy is a question of give and take  \n",
      "You can learn how to show it so come on, giv...\n",
      "  Original prediction: <pad> joy\n",
      "  Probability distribution:\n",
      "    joy       : 0.7256 (72.56%)\n",
      "    love      : 0.2522 (25.22%)\n",
      "    anger     : 0.0192 (1.92%)\n",
      "    sadness   : 0.0019 (0.19%)\n",
      "    surprise  : 0.0001 (0.01%)\n",
      "    fear      : 0.0001 (0.01%)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing songs:  50%|█████     | 5/10 [00:04<00:04,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Song 5:\n",
      "  Text preview: Making somebody happy is a question of give and take  \n",
      "You can learn how to show it so come on, giv...\n",
      "  Original prediction: <pad> joy\n",
      "  Probability distribution:\n",
      "    joy       : 0.7391 (73.91%)\n",
      "    love      : 0.1810 (18.10%)\n",
      "    anger     : 0.0634 (6.34%)\n",
      "    sadness   : 0.0148 (1.48%)\n",
      "    fear      : 0.0001 (0.01%)\n",
      "    surprise  : 0.0001 (0.01%)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing songs:  60%|██████    | 6/10 [00:05<00:03,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Song 6:\n",
      "  Text preview: Well, you hoot and you holler and you make me mad  \n",
      "And I've always been under your heel  \n",
      "Holy ch...\n",
      "  Original prediction: <pad> anger\n",
      "  Probability distribution:\n",
      "    anger     : 0.6258 (62.58%)\n",
      "    sadness   : 0.3524 (35.24%)\n",
      "    joy       : 0.0178 (1.78%)\n",
      "    fear      : 0.0018 (0.18%)\n",
      "    love      : 0.0011 (0.11%)\n",
      "    surprise  : 0.0001 (0.01%)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing songs:  70%|███████   | 7/10 [00:06<00:02,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Song 7:\n",
      "  Text preview: Down in the street they're all singing and shouting  \n",
      "Staying alive though the city is dead  \n",
      "Hidi...\n",
      "  Original prediction: <pad> sadness\n",
      "  Probability distribution:\n",
      "    sadness   : 0.9485 (94.85%)\n",
      "    joy       : 0.0219 (2.19%)\n",
      "    anger     : 0.0129 (1.29%)\n",
      "    fear      : 0.0096 (0.96%)\n",
      "    love      : 0.0053 (0.53%)\n",
      "    surprise  : 0.0002 (0.02%)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing songs:  80%|████████  | 8/10 [00:07<00:01,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Song 8:\n",
      "  Text preview: Chiquitita, tell me what's wrong  \n",
      "You're enchained by your own sorrow  \n",
      "In your eyes there is no ...\n",
      "  Original prediction: <pad> sadness\n",
      "  Probability distribution:\n",
      "    sadness   : 0.9723 (97.23%)\n",
      "    joy       : 0.0147 (1.47%)\n",
      "    fear      : 0.0053 (0.53%)\n",
      "    anger     : 0.0032 (0.32%)\n",
      "    love      : 0.0031 (0.31%)\n",
      "    surprise  : 0.0001 (0.01%)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing songs:  90%|█████████ | 9/10 [00:08<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Song 9:\n",
      "  Text preview: I was out with the morning sun  \n",
      "Couldn't sleep, so I thought I'd take a walk  \n",
      "I was thinking of ...\n",
      "  Original prediction: <pad> surprise\n",
      "  Probability distribution:\n",
      "    surprise  : 0.8947 (89.47%)\n",
      "    fear      : 0.0561 (5.61%)\n",
      "    joy       : 0.0228 (2.28%)\n",
      "    anger     : 0.0130 (1.30%)\n",
      "    sadness   : 0.0093 (0.93%)\n",
      "    love      : 0.0010 (0.10%)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing songs: 100%|██████████| 10/10 [00:08<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Song 10:\n",
      "  Text preview: I'm waitin' for you baby  \n",
      "I'm sitting all alone  \n",
      "I feel so cold without you  \n",
      "It chills me to t...\n",
      "  Original prediction: <pad> anger\n",
      "  Probability distribution:\n",
      "    anger     : 0.9965 (99.65%)\n",
      "    sadness   : 0.0026 (0.26%)\n",
      "    love      : 0.0004 (0.04%)\n",
      "    fear      : 0.0003 (0.03%)\n",
      "    joy       : 0.0001 (0.01%)\n",
      "    surprise  : 0.0000 (0.00%)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✓ Processing complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply the emotion distribution function to first 10 songs\n",
    "from tqdm import tqdm\n",
    "\n",
    "emotion_distributions = []\n",
    "\n",
    "for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Processing songs\"):\n",
    "    text = row['text']\n",
    "    \n",
    "    # Get emotion distribution\n",
    "    emotion_dist = get_emotion_distribution(text)\n",
    "    emotion_distributions.append(emotion_dist)\n",
    "    \n",
    "    # Also get the original single-label prediction for comparison\n",
    "    single_label = get_emotion(text)\n",
    "    \n",
    "    # Print results for each song\n",
    "    print(f\"\\nSong {idx + 1}:\")\n",
    "    print(f\"  Text preview: {text[:100]}...\")\n",
    "    print(f\"  Original prediction: {single_label}\")\n",
    "    print(f\"  Probability distribution:\")\n",
    "    for emotion, prob in sorted(emotion_dist.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"    {emotion:10}: {prob:.4f} ({prob*100:.2f}%)\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Add emotion distribution as a new column\n",
    "test_df['emotion_distribution'] = emotion_distributions\n",
    "\n",
    "print(\"\\n✓ Processing complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe78150",
   "metadata": {},
   "source": [
    "## Save Results to CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc60eab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Results saved to: datasets/lyrics_mood_with_distributions_10songs.csv\n",
      "\n",
      "DataFrame shape: (10, 11)\n",
      "\n",
      "Columns in output:\n",
      "  - artist\n",
      "  - song\n",
      "  - link\n",
      "  - text\n",
      "  - emotion_distribution\n",
      "  - prob_joy\n",
      "  - prob_sadness\n",
      "  - prob_anger\n",
      "  - prob_fear\n",
      "  - prob_love\n",
      "  - prob_surprise\n",
      "\n",
      "================================================================================\n",
      "SUMMARY OF FIRST 10 SONGS\n",
      "================================================================================\n",
      "                                                text  prob_joy  prob_sadness  \\\n",
      "0  Look at her face, it's a wonderful face  \\r\\nA...  0.999586      0.000019   \n",
      "1  Take it easy with me, please  \\r\\nTouch me gen...  0.038810      0.000266   \n",
      "2  I'll never know why I had to go  \\r\\nWhy I had...  0.048142      0.933231   \n",
      "3  Making somebody happy is a question of give an...  0.725644      0.001899   \n",
      "4  Making somebody happy is a question of give an...  0.739095      0.014799   \n",
      "5  Well, you hoot and you holler and you make me ...  0.017800      0.352353   \n",
      "6  Down in the street they're all singing and sho...  0.021921      0.948496   \n",
      "7  Chiquitita, tell me what's wrong  \\r\\nYou're e...  0.014696      0.972311   \n",
      "8  I was out with the morning sun  \\r\\nCouldn't s...  0.022802      0.009298   \n",
      "9  I'm waitin' for you baby  \\r\\nI'm sitting all ...  0.000091      0.002595   \n",
      "\n",
      "     prob_anger     prob_fear  prob_love  prob_surprise  \n",
      "0  5.837727e-07  2.677541e-07   0.000284       0.000002  \n",
      "1  5.198388e-05  1.128953e-05   0.960187       0.000064  \n",
      "2  1.226215e-02  3.051568e-03   0.002106       0.000144  \n",
      "3  1.923788e-02  5.918782e-05   0.252175       0.000094  \n",
      "4  6.342337e-02  1.132685e-04   0.180972       0.000105  \n",
      "5  6.257569e-01  1.842340e-03   0.001085       0.000090  \n",
      "6  1.292296e-02  9.610198e-03   0.005253       0.000244  \n",
      "7  3.168998e-03  5.347073e-03   0.003122       0.000133  \n",
      "8  1.297585e-02  5.607091e-02   0.000995       0.894708  \n",
      "9  9.964767e-01  3.109074e-04   0.000408       0.000025  \n"
     ]
    }
   ],
   "source": [
    "# Also create separate columns for each emotion probability for easier analysis\n",
    "for emotion in EMOTION_IDS.keys():\n",
    "    test_df[f'prob_{emotion}'] = test_df['emotion_distribution'].apply(lambda x: x[emotion])\n",
    "\n",
    "# Save to CSV\n",
    "output_file = 'datasets/lyrics_mood_with_distributions_10songs.csv'\n",
    "test_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✓ Results saved to: {output_file}\")\n",
    "print(f\"\\nDataFrame shape: {test_df.shape}\")\n",
    "print(f\"\\nColumns in output:\")\n",
    "for col in test_df.columns:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY OF FIRST 10 SONGS\")\n",
    "print(\"=\" * 80)\n",
    "print(test_df[['text', 'prob_joy', 'prob_sadness', 'prob_anger', 'prob_fear', 'prob_love', 'prob_surprise']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540dc55f",
   "metadata": {},
   "source": [
    "## Validation: Check that probabilities sum to ~1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "705f6902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Sum of all emotion probabilities for each song\n",
      "================================================================================\n",
      "        prob_sum\n",
      "count  10.000000\n",
      "mean    0.998875\n",
      "std     0.000872\n",
      "min     0.996851\n",
      "25%     0.998576\n",
      "50%     0.998932\n",
      "75%     0.999319\n",
      "max     0.999906\n",
      "\n",
      "✓ All probability sums:\n",
      "  Song 1: 0.999892 (99.99%)\n",
      "  Song 2: 0.999389 (99.94%)\n",
      "  Song 3: 0.998938 (99.89%)\n",
      "  Song 4: 0.999109 (99.91%)\n",
      "  Song 5: 0.998508 (99.85%)\n",
      "  Song 6: 0.998927 (99.89%)\n",
      "  Song 7: 0.998447 (99.84%)\n",
      "  Song 8: 0.998779 (99.88%)\n",
      "  Song 9: 0.996851 (99.69%)\n",
      "  Song 10: 0.999906 (99.99%)\n",
      "\n",
      "✓✓ SUCCESS: All probabilities sum to approximately 1.0!\n"
     ]
    }
   ],
   "source": [
    "# Validate that probabilities sum to approximately 1.0\n",
    "prob_cols = ['prob_joy', 'prob_sadness', 'prob_anger', 'prob_fear', 'prob_love', 'prob_surprise']\n",
    "test_df['prob_sum'] = test_df[prob_cols].sum(axis=1)\n",
    "\n",
    "print(\"Validation: Sum of all emotion probabilities for each song\")\n",
    "print(\"=\" * 80)\n",
    "print(test_df[['prob_sum']].describe())\n",
    "\n",
    "print(\"\\n✓ All probability sums:\")\n",
    "for idx, row in test_df.iterrows():\n",
    "    print(f\"  Song {idx + 1}: {row['prob_sum']:.6f} ({row['prob_sum']*100:.2f}%)\")\n",
    "\n",
    "if (test_df['prob_sum'] > 0.99).all() and (test_df['prob_sum'] < 1.01).all():\n",
    "    print(\"\\n✓✓ SUCCESS: All probabilities sum to approximately 1.0!\")\n",
    "else:\n",
    "    print(\"\\n⚠ WARNING: Some probability sums are outside expected range.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc396",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
