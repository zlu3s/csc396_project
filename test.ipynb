{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef379397-4c75-4aee-a3d1-7b3c5c4f1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "# enable tqdm in pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# set to True to use the gpu (if there is one available)\n",
    "use_gpu = True\n",
    "\n",
    "# select device\n",
    "device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {device.type}')\n",
    "\n",
    "# random seed\n",
    "seed = 1234\n",
    "\n",
    "# set random seed\n",
    "if seed is not None:\n",
    "    print(f'random seed: {seed}')\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f620b70f-29db-4ee2-aa3c-668bfcab00a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "name = './roberta-base-sentiments'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(name)\n",
    "model = RobertaForSequenceClassification.from_pretrained(name)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe023c-dead-4aba-a72a-b95925967d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "# Songs\n",
    "kg_songs = load_dataset(\"csv\", data_files=\"datasets/songs.csv\")\n",
    "kg_songs = kg_songs[\"train\"].to_pandas()\n",
    "\n",
    "\n",
    "# Poems\n",
    "hf_mteb = load_dataset(\"mteb/PoemSentimentClassification\")\n",
    "hf_mteb = hf_mteb[\"train\"].to_pandas()\n",
    "\n",
    "kg_poems = load_dataset(\"csv\", data_files=\"datasets/final_df_emotions(remove-bias).csv\")\n",
    "kg_poems = kg_poems[\"train\"].to_pandas()\n",
    "\n",
    "md_perc = pd.read_excel(\"datasets/PERC_mendelly.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a2c9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_songs = kg_songs.rename(columns={\"mood\": \"label\", \"lyrics\": \"text\"})\n",
    "md_perc = md_perc.rename(columns={\"Emotion\": \"label\"})\n",
    "\n",
    "labels = [\"sad\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "label_map = {\n",
    "    \"sad\": \"sad\",\n",
    "    \"sadness\": \"sad\",\n",
    "    \"joy\": \"joy\",\n",
    "    \"happy\": \"joy\",\n",
    "    \"love\": \"love\",\n",
    "    \"romantic\": \"love\",\n",
    "    \"anger\": \"anger\",\n",
    "    \"angry\": \"anger\",\n",
    "    \"fear\": \"fear\",\n",
    "    \"surprise\": \"surprise\",\n",
    "    \"excited\": \"surprise\"\n",
    "}\n",
    "\n",
    "def adjust_labels(df, label_col, label_map):\n",
    "    df[label_col] = df[label_col].map(label_map)\n",
    "    return df[df[label_col].isin(labels)].reset_index(drop=True)\n",
    "\n",
    "kg_songs = adjust_labels(kg_songs, \"label\", label_map)\n",
    "hf_mteb = adjust_labels(hf_mteb, \"label\", label_map)\n",
    "kg_poems = adjust_labels(kg_poems, \"label\", label_map)\n",
    "md_perc = adjust_labels(md_perc, \"label\", label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c231d9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kg_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "342bb5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5033639b5f794a7b8431df9d224d051a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/498 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "def tokenize(dataset):\n",
    "    return tokenizer(dataset['text'], truncation=True)\n",
    "\n",
    "kg_songs_ds = Dataset.from_pandas(kg_songs)\n",
    "test1 = kg_songs_ds.map(\n",
    "    tokenize, batched=True,\n",
    "    remove_columns=['song_name', 'artist'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d55f608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 498\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed4ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model)\n",
    "output = trainer.predict(test1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
